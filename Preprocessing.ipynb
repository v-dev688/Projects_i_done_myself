{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<b>SOME PRE PROCESSING STEPS</b>\n",
        "\n",
        "\n",
        "Outlier removal<br>\n",
        "Scaling<br>\n",
        "One-hot encoding<br>\n",
        "ordinal encoding<br>\n",
        "oversampling and under sampling<br>"
      ],
      "metadata": {
        "id": "qI0SRyvip9tb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<b> 1. Imputation of missing values<br>"
      ],
      "metadata": {
        "id": "iOXe44ALj_Cg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FOR CATEGORICAL VARIABLES\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "for column in df.select_dtypes(include='object').columns:\n",
        "    mode_value = df[column].mode()[0]\n",
        "    df[column].fillna(mode_value, inplace=True)\n"
      ],
      "metadata": {
        "id": "P3DhaQi_it1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FOR NUMERICAL SKEWED\n",
        "\n",
        "skewed_columns = ['Column1', 'Column2', 'Column3']\n",
        "df[skewed_columns] = df[skewed_columns].fillna(df[skewed_columns].median())\n",
        "\n",
        "# FOR NUMERICAL NON- SKEWED"
      ],
      "metadata": {
        "id": "YcSNw_WVjK1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b>2. OUTLIER REMOVAL"
      ],
      "metadata": {
        "id": "E1BMAT88kHP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "numerical_columns = ['Column1', 'Column2', 'Column3']\n",
        "z_scores = stats.zscore(df[numerical_columns])\n",
        "\n",
        "threshold = 3\n",
        "\n",
        "outlier_indices = (z_scores > threshold) | (z_scores < -threshold)\n",
        "\n",
        "df_no_outliers = df[~outlier_indices.any(axis=1)]\n",
        "\n",
        "# Print the number of removed outliers\n",
        "print(\"Number of removed outliers:\", sum(outlier_indices.any(axis=1)))\n"
      ],
      "metadata": {
        "id": "7-4Mm3pUkYs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using IQR\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "numerical_columns = ['Column1', 'Column2', 'Column3']\n",
        "\n",
        "# Calculate the first quartile (Q1) and third quartile (Q3)\n",
        "Q1 = df[numerical_columns].quantile(0.25)\n",
        "Q3 = df[numerical_columns].quantile(0.75)\n",
        "\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "outlier_indices = ((df[numerical_columns] < lower_bound) | (df[numerical_columns] > upper_bound))\n",
        "\n",
        "# Remove outliers from the DataFrame\n",
        "df_no_outliers = df[~outlier_indices.any(axis=1)]\n",
        "\n",
        "# Print the number of removed outliers\n",
        "print(\"Number of removed outliers:\", sum(outlier_indices.any(axis=1)))\n",
        "\n",
        "# df_no_outliers is the DataFrame with outliers removed\n"
      ],
      "metadata": {
        "id": "faTErmjVkvIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <b> SCALING AND TRANSFORMATION"
      ],
      "metadata": {
        "id": "5olqcq9hm3Um"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming df is your DataFrame with numerical columns\n",
        "# Replace df with your actual DataFrame\n",
        "\n",
        "# Specify the numerical columns for standardization\n",
        "numerical_columns = ['Column1', 'Column2', 'Column3']\n",
        "\n",
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the numerical data and transform it\n",
        "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
        "\n"
      ],
      "metadata": {
        "id": "uZmoMjMUmmSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<b> ORDINAL ENCODING"
      ],
      "metadata": {
        "id": "-n4gaEd1oSjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming df is your DataFrame with a categorical column\n",
        "# Replace df with your actual DataFrame\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {'Category': ['Low', 'Medium', 'High', 'Low', 'High', 'Medium']}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Initialize the OrdinalEncoder\n",
        "ordinal_encoder = OrdinalEncoder(categories=[['Low', 'Medium', 'High']])\n",
        "\n",
        "# Fit and transform the categorical column\n",
        "df['Category_encoded'] = ordinal_encoder.fit_transform(df[['Category']])\n",
        "\n",
        "# Display the DataFrame with ordinal encoding\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cA2jc0VVojgU",
        "outputId": "8377d280-5aa1-4c90-9fbb-b7608e4c0902"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Category  Category_encoded\n",
            "0      Low               0.0\n",
            "1   Medium               1.0\n",
            "2     High               2.0\n",
            "3      Low               0.0\n",
            "4     High               2.0\n",
            "5   Medium               1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b> PERFORMANCE EVALUATION"
      ],
      "metadata": {
        "id": "cFV7gR26yLV1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b> oversampling and under sampling"
      ],
      "metadata": {
        "id": "ROowMhlaoyKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (OVERSAMPLING )increase the number of minority class\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "\n",
        "# Random Oversampling\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
        "\n",
        "# SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n"
      ],
      "metadata": {
        "id": "EG57r_A2o1X_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (UNDERSAMPLING )increase the number of minority class\n",
        "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
        "\n",
        "# Random Undersampling\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
        "\n",
        "# NearMiss\n",
        "nm = NearMiss(version=1)\n",
        "X_resampled, y_resampled = nm.fit_resample(X, y)\n"
      ],
      "metadata": {
        "id": "5J-dzQQ0pRFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<b> 5 MULTICOLINEARITY"
      ],
      "metadata": {
        "id": "DtiOn11fsHs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import  variance_inflation_factor\n",
        "vif=[]\n",
        "for i in range(X.shape[1]):\n",
        "  vif.append(variance_inflation_factor(X.values,i))\n",
        "\n",
        "pd.DataFrame({\"Feature\": X.columns, \"VIF\":vif}).sort_values(by=\"VIF\", ascending=False)"
      ],
      "metadata": {
        "id": "Vu4HwLLEsPTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<b> 6. DROP_DUPLICATES"
      ],
      "metadata": {
        "id": "fURVarfZsfne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a sample DataFrame with duplicate rows\n",
        "data = {'A': [1, 2, 3, 1, 2, 3],\n",
        "        'B': ['X', 'Y', 'Z', 'X', 'Y', 'Z']}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the original DataFrame\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "\n",
        "# Drop duplicate rows\n",
        "df_no_duplicates = df.drop_duplicates()\n",
        "\n",
        "# Display the DataFrame after dropping duplicates\n",
        "print(\"\\nDataFrame after dropping duplicates:\")\n",
        "print(df_no_duplicates)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eY8-3tPXsk_C",
        "outputId": "e3edacc0-5038-497d-d00c-bc132c3dab55"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame:\n",
            "   A  B\n",
            "0  1  X\n",
            "1  2  Y\n",
            "2  3  Z\n",
            "3  1  X\n",
            "4  2  Y\n",
            "5  3  Z\n",
            "\n",
            "DataFrame after dropping duplicates:\n",
            "   A  B\n",
            "0  1  X\n",
            "1  2  Y\n",
            "2  3  Z\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>7. FiNding the value of K(KNN)"
      ],
      "metadata": {
        "id": "FzeaUwQ4tX51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Define a range of k values to search\n",
        "k_values = list(range(1, 21))\n",
        "\n",
        "# Create a parameter grid\n",
        "param_grid = {'n_neighbors': k_values}\n",
        "\n",
        "# Initialize the KNN classifier\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(knn_classifier, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best value of k from the grid search\n",
        "best_k = grid_search.best_params_['n_neighbors']\n",
        "best_k\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FikQZGZEtiJh",
        "outputId": "06d25663-90e1-4729-b5ae-8cfb0b71f6cb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b> 8. Validation and Cross-Validation in  Random Forest"
      ],
      "metadata": {
        "id": "T7rP_iq6uVeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming X and y are your features and target variable\n",
        "# Replace X and y with your actual data\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model on the training set\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the validation set\n",
        "y_pred = rf_classifier.predict(X_valid)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "accuracy = accuracy_score(y_valid, y_pred)\n",
        "print(f\"Validation Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdS8x8Anub-v",
        "outputId": "f7d86981-7d86-4bbe-c7b8-31f4ac9a6d0c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cross_validation\n",
        "\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Assuming X and y are your features and target variable\n",
        "# Replace X and y with your actual data\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Perform cross-validation (e.g., with 5 folds)\n",
        "cross_val_accuracies = cross_val_score(rf_classifier, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "# Print cross-validation results\n",
        "print(\"Cross-Validation Accuracies:\", cross_val_accuracies)\n",
        "print(\"Mean Accuracy:\", cross_val_accuracies.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCv8J8NZuf8V",
        "outputId": "2e164aa2-96d4-4b3b-b42e-66cb1f0c6bef"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Accuracies: [0.96666667 0.96666667 0.93333333 0.96666667 1.        ]\n",
            "Mean Accuracy: 0.9666666666666668\n"
          ]
        }
      ]
    }
  ]
}